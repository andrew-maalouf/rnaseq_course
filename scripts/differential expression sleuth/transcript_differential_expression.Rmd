inspired by imported walkthrough and website: https://hbctraining.github.io/DGE_workshop_salmon/lessons/09_sleuth.html

Requirements for this walkthrough:

- `cowplot` for making prettier plots and plots with grids. Available in CRAN:  `install.packages('cowplot')`.
- `biomaRt` for extracting the Ensembl transcript to gene mapping.

To install the package:

```{r eval=FALSE}
if (!require("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install()

BiocManager::install(c("biocLite","biomaRt"))

library(biomaRt)
```

The walkthrough begins after the RNA-Seq samples have been quantified with kallisto. Kallisto is very fast in quantifying samples. Kallisto quantifications have been downloaded for the relevant samples.
Let's load the requisite packages:

My analysis was run using:
biomaRt_2.58.0
cowplot_1.1.2
sleuth_0.30.1
EnhancedVolcano_1.20.0
ggrepel_0.9.4
ggplot2_3.4.4

```{r warning=FALSE}
suppressMessages({
  library('cowplot')
  library('sleuth')
})
```

## Parsing metadata

A sleuth analysis is dependent on a metadata file, which describes the experimental design, the sample names, conditions and covariates. The metadata file is external to sleuth, and must be prepared prior to analysis. A metadata file should have been downloaded along with the kallisto quantifications.  The first step in a sleuth analysis is loading of the metadata file. You might need the path in read_table below to where you have downloaded the kallisto dataset, so that the path directs to the sample_table.txt. We then select the relevant columns of the metadata.


```{r}
metadata <- read.table('C:/Users/user/Desktop/UniBe/Semester_1/Bern/RNA_sequencing/Project1_lncRNA/step5_differential_expression/running_sleuth/experimental_design.txt', sep='\t', header=TRUE, stringsAsFactors = FALSE)
metadata <- dplyr::select(metadata, c('sample_id', 'condition'))
```

```{r}
head(metadata, n = 20)
```

This file describes the experimental design.
We are concerned with one major experimental condition: holoclonal vs parental. Combinatorially, we could have a possible of 2^1 = 2 conditions. For each condition, three biological replicates were sequenced, so we have a total of 6 samples.
The column 'condition' lists the subtype of cell: holoclonal or parental. 
The 'sample_id' column is the replicate name. The kallisto quantifications are titled with these replicates names.


Finally, we add the path names of the kallisto output directories to the metadata table. We use the replicate names listed under sample_id to identify the folders we must use for the correpsonding kallisto quantifications:

```{r}
metadata <- dplyr::mutate(metadata,
  path = file.path('C:/Users/user/Desktop/UniBe/Semester_1/Bern/RNA_sequencing/Project1_lncRNA/step5_differential_expression/running_sleuth/kallisto_results', sample_id))
head(metadata)
```

It is important to spot check the metadata file again to make sure that the kallisto runs correspond to the accession numbers in the table, so that each row is associated with the correct sample.

We rename the 'sample_id' column to 'sample.' 'sample' and 'path' are the two column names that sleuth will need to find the sample name and the path of the kallisto qunatifications.

```{r}
metadata <- dplyr::rename(metadata, sample = sample_id)
head(metadata)
```

## Provide the model design
Now that we have the metadata and location of the count estimates, we can input our design formula to determine the covariates and/or confounders that should be included in your experimental design model. Sleuth can be used to analyze multiple conditions from complex experimental designs.

Within Sleuth, models are written similar to DESeq2. Since the only condition we plan to test is our sample type, our design formula is very simple:

```{r}
design <- ~ condition
```


## Query annotables dataset to obtain the corresponding Ensembl transcript/gene IDs
## Associating transcripts to genes

The sample quantifications performed by kallisto have produced transcript abundance and count estimates.
These have been parsed by sleuth in the steps just performed, however sleuth does not "know" about genes yet.

The last component to include for our analysis is the annotable to obtain the transcript/gene IDs and gene names and biotypes for annotation of results. 

Again, we will need to provide column names that are consistent with what Sleuth is expecting.

For this, I will use my own csv file.

This dataframe contains gene_id, transcript IDs, gene names and biotype, without header, so I will have to add a header for sleuth to work with it.

```{r}
my_csv_file <- read.csv('C:/Users/user/Desktop/UniBe/Semester_1/Bern/RNA_sequencing/Project1_lncRNA/table.csv', sep = " ", header = FALSE, stringsAsFactors = FALSE)

#column names are V1 V2 V3 V4; hence, rename them for myself
my_csv_file <- dplyr::rename(my_csv_file, gene_id = V2, transcript_id = V1, gene_name = V3, biotype = V4)

#now rename it properly for sleuth (it could have been done since the start, but i like it when i see it in front of me)
my_csv_file <- dplyr::rename(my_csv_file, target_id = transcript_id, ens_gene = gene_id, ext_gene = gene_name)
 
#keep the first 3 columns, without biotype
my_csv_file <- dplyr::select(my_csv_file, c('target_id', 'ens_gene', 'ext_gene', 'biotype'))
 
head(my_csv_file)
```

The resulting table contains Ensembl gene names ('ens_gene') and the associated transcripts ('target_id'). Note that the gene-transcript mapping must be compatible with the transcriptome used with kallisto.



## Fit the sleuth model

Now we need to tell sleuth both about the kallisto results and the gene names (and gene description/metadata) we obtained. The "sleuth_prep" function does this

Fit the transcript abundance data to the Sleuth model
Using the sleuth_prep() function, the counts are normalized and filtered, then merged with the metadata. In addition, the bootstraps for each transcript are summarized. This function can take a bit of time, but there is an option (ncores) to split across multiple processors.

NOTE: By default the transformation of counts is natural log, which would make the output fold changes somewhat more difficult to interpret. By specifying the transformation_function to be log2(x + 0.5) we are ensuring our output fold changes are log2.

```{r}
# Create sleuth object for analysis 

so <- sleuth_prep(metadata, 
                  full_model = design, 
                  target_mapping = my_csv_file, 
                  read_bootstrap_tpm = TRUE,
                  extra_bootstrap_summary = TRUE,
                  transformation_function = function(x) log2(x + 0.5))
```

In fitting the sleuth model, sleuth performs shrinkage of variance, parameter estimation and estimation of variance using the general linear model:

```{r}
so <- sleuth_fit(so)
```


Check which models have been fit and which coefficients can be tested
Ensure the design model and coefficients are correct for your analysis. The level not shown is the base level.


```{r}
models(so)
```
I am satisfied, since I want coefficient: "conditionparental"

NOTE: Sleuth will automatically use the first level (alphabetically by default) in the factor variable being tested to compare all other conditions against (in our metadata, this is ‘control’). If you want to use a different condition to be the base level, then you would need to use the relevel() function to change the base level of the variable in step 1 above. For example, if we wanted the base level of condition to be parental, we could use the following code: (replace parental with holoclonal)


```{r}
# DO NOT RUN!
# DO NOT RUN!
# DO NOT RUN!
# DO NOT RUN!
metadata$condition <- relevel(metadata$condition, ref = "parental")
```

## Step 3: Test significant differences between conditions using the Wald test

###Examine Sleuth PCA

next, we should check to see if our samples (and replicates) cluster on PCA (as should expect) or if there are outliers. When we plot by condition, we'd expect that similar colors group together.

```{r}
library(cowplot)
ggplot2::theme_set(theme_cowplot())
plot_pca(so, color_by = "condition", text_labels = F)
```



At this step in the workflow, we need to specify which level we want to compare against the base level (use the name given for the coefficients from models(so)):

```{r}
# Wald test for differential expression of isoforms

oe <- sleuth_wt(so, 
                which_beta = 'conditionparental')

# output results

sleuth_results_oe <- sleuth_results(oe, 
                                    test = 'conditionparental', 
                                    show_all = TRUE)
```

```{r}
head(sleuth_results_oe, 20)
```



## Exploring transcript-level expression between samples
Exploratory analyses:
Now that we have our results, we can perform some exploratory analyses, such as PCA, heatmap, and distributions of counts between conditions. By default, these plots will use the sleuth-normalized est_counts (not the log2 transformed values).

PCA: There are multiple functions to explore the variation in the dataset explained by the different PCs.

```{r}
plot_pc_variance(oe)
```


```{r}
plot_loadings(oe)
```

Heatmap: The heatmap plot is shaded with the Jensen-Shannon divergence values. Therefore, lower divergence values represent samples that are more similar to each other.

```{r}
plot_sample_heatmap(oe, use_filtered = T, cluster_bool = F)
```


Count distributions: There is a histogram plot to explore count distributions between sample groups, which should be similar to each other when performing DE testing. The count distributions represent the proportion of genes (on the y-axis) associated with the number of counts (designated on the x-axis):
```{r}
plot_group_density(oe, 
                   use_filtered = FALSE, 
                   units = "est_counts",
                   trans = "log", 
                   grouping = "condition")
```

As we know, most genes have few counts, but we filter these genes prior to performing DE analysis. If we want to look at the distributions of the filtered genes used for DE analysis, we could change the use_filtered argument to TRUE.

```{r}
plot_group_density(oe, 
                   use_filtered = TRUE, 
                   units = "est_counts",
                   trans = "log", 
                   grouping = "condition")
```


Results analyses:
There are also functions to explore the results. For example, we can perform an expression heatmap for select transcripts:
```{r}
library(dplyr)
library(magrittr)

sig_transcripts <- sleuth_results_oe %>% 
  filter(qval < 0.05)
  
plot_transcript_heatmap(oe, 
                        transcripts = sig_transcripts$target_id[1:20])
```

Sleuth also has some handy functions to plot expression of transcripts with bootstrap variation to visualize both biological and technical variation for selected transcripts:

```{r}
# Plotting

plot_bootstrap(oe, 
               target_id = "ENST00000262067.5", 
               units = "est_counts", 
               color_by = "condition")

plot_bootstrap(oe, 
               target_id = "ENST00000401412.5", 
               units = "est_counts", 
               color_by = "condition")

plot_bootstrap(oe, 
               target_id = "ENST00000641036.1", 
               units = "est_counts", 
               color_by = "condition")


plot_bootstrap(oe, 
               target_id = "ENST00000587762.2", 
               units = "est_counts", 
               color_by = "condition")

plot_bootstrap(oe, 
               target_id = "ENST00000371817.8", 
               units = "est_counts", 
               color_by = "condition")

#sox2
plot_bootstrap(oe, 
               target_id = "ENST00000325404.3", 
               units = "est_counts", 
               color_by = "condition")

plot_bootstrap(oe, 
               target_id = "MSTRG.1579.1", 
               units = "est_counts", 
               color_by = "condition")

plot_bootstrap(oe, 
               target_id = "MSTRG.18044.1", 
               units = "est_counts", 
               color_by = "condition")

```

Sleuth also offers us the option to explore the data and results interactively using a web interface.
```{r}
sleuth_live(oe)
```


This will open a new browser that runs the R shiny app. One can visualize the transcript dynamics that resulted in these gene differential results under 'analysis' -> 'gene view.' Enterring the Ensembl gene name and selecting 'ens_gene' from the 'genes from' dropdown will display each transcript corresponding to that gene. 'analyses' -> 'test table' will provide the same results as sleuth_table.  As we previously mentioned, because our gene results are based on the transcript results, there is no need to visualize gene abundances separately. Instead, one can use the transcript abundances as the evidence for the gene level differential expression.



DONE

now I'll add here some code to get volcano plot and heatmap separately

first we will install "enhancedvolcano"

```{r}
if (!requireNamespace('BiocManager', quietly = T))
  install.packages('BiocManager')

BiocManager::install('EnhancedVolcano')
```

now i load it

```{r}
library(EnhancedVolcano)
```

now let's plot it
1: name of our data table
2: x values : log2FoldChange -> B
3: y p adjusted aka qval
 

```{r}
EnhancedVolcano(sleuth_results_oe, 
                x = "b", 
                y = "qval", 
                lab = sleuth_results_oe$target_id,
                legendLabels = c("NS", expression(Log[2] ~ FC), "adj p-value", expression(adj~p - value ~ and ~ log[2] ~ FC)),
                subtitle = bquote(italic(Transcript~Level)),
                drawConnectors = T,
                pointSize = 1.0,
                labSize = 2.0,
                legendPosition = 'none',
                )
```
now if i want to change threshold

```{r}
EnhancedVolcano(sleuth_results_oe, 
                x = "b", 
                y = "qval", 
                lab = sleuth_results_oe$ext_gene,
                pCutoff = 1e-4,
                FCcutoff = 0.05)
```

now if i want to label specific genes only, i start by making a vector
```{r}
select <- c("CD44", "SOX2", "ABCG2", "COL5A1", "POU5F1", "CDH1", "CDH17", "CD274", "EPCAM", "MYC", "MYCL")
EnhancedVolcano(sleuth_results_oe, 
                x = "b", 
                y = "qval", 
                lab = sleuth_results_oe$ext_gene,
                pCutoff = 0.1,
                FCcutoff = 1,
                selectLab = select)
```

DONE
DONE

